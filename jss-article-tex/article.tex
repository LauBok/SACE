\documentclass[article]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{thumbpdf,lmodern}

%% another package (only for this demo article)
\usepackage{framed}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}
\def\ci{\perp\!\!\!\perp}
\def\nci{\not\!\perp\!\!\!\perp}
\def\expit{\mathrm{expit}}
\newcommand{\transpose}[1]{#1^{\mathrm{T}}}


%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Bo Liu\thanks{Equally contributed} \\ Peking University
   \And Zhixuan Shao$^*$ \\ Peking University
   \And Xiaohua Zhou\thanks{Corresponding Author} \\ Peking University}
\Plainauthor{Bo Liu, Zhixuan Shao, Xiaohua Zhou}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{MIE: An approach to obtaining causal effect estimation in \proglang{R}}
\Plaintitle{MIE: An approach to obtaining causal effect estimation in R}
\Shorttitle{MIE: An approach to obtaining causal effect estimation in R}

%% - \Abstract{} almost as usual
\Abstract{
  
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{causal effect, survival, treatment, substitution variable, \proglang{R}}
\Plainkeywords{causal effect, survival, treatment, substitution variable, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  Xiaohua Zhou\\
  Professor\\
  Beijing International Center for Mathematical Research\\
  Peking University \\
  5 Yiheyuanlu Road \\
  100871 Beijing, China\\
  E-mail: \email{azhou@bicmr.pku.edu.cn}\\
  URL: \url{http://faculty.washington.edu/azhou}
}

\begin{document}


%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, and \code{} markup throughout the manuscript.
%% - If such markup is in (sub)section titles, a plain text version has to be
%%   added as well.
%% - All software mentioned should be properly \cite-d.
%% - All abbreviations should be introduced.
%% - Unless the expansions of abbreviations are proper names (like "Journal
%%   of Statistical Software" above) they should be in sentence case (like
%%   "generalized linear models" below).

\section[Introduction: Count data regression in R]{Introduction} \label{sec:intro}


Researches regarding causal effect allure much attention of statisticians due to its various applications in scholarship as well as industry. In the field of biostatistics, one essential application is to determine the causal effect on outcomes a specific treatment may exert. However, the distinguishing charisteristic of ineluctable deaths among the examinees may possibly invalidate the identifiablity of the group we focus on, where patients will survive both with and without the treatment. A number of new methods have been proposed to eliminate the obstacle. One pertinent paper \cite{Wang2017Identification} suggests the identifiablity can be vindicated by introducing a substitution variable, and both the estimated causal effect and its asymptic variance are provided. The R package (?) is designed in light of this method.

The paper is organized as follows. Section 2 retraces the model implemented in the package, Section 3 focuses on the data types and functions of the package, and Section 4 provides formulas on calculating variances in a more detailed manner. In Section 5, a specific dataset is generated and tested by the method, and explanations about the results will be analysed in Section 6.


%% -- Manuscript ---------------------------------------------------------------

%% - In principle "as usual" again.
%% - When using equations (e.g., {equation}, {eqnarray}, {align}, etc.
%%   avoid empty lines before and after the equation (which would signal a new
%%   paragraph.
%% - When describing longer chunks of code that are _not_ meant for execution
%%   (e.g., a function synopsis or list of arguments), the environment {Code}
%%   is recommended. Alternatively, a plain {verbatim} can also be used.
%%   (For executed code see the next section.)

\section{The Causal Effect Model} \label{sec:model}
\subsection{Survivor Average Causal Effect(SACE)}

Consider a trail for a treatment with a single follow-up visit. Let $Z$ be the exposure indicator to the treatment, i.e., $Z=1$ means the patient receives the treatment and $Z=0$ means not. Each patient may have two potential survival statuses $S(1)$ and $S(0)$, defined as whether the patient would be alive at the time of follow-up visit had the subject been exposed or not respectively. \cite{Hernan265} has defined the causal effect to be $\mathbb{E}(S(1))-\mathbb{E}(S(0))$, which indicates the difference in the probability of survival between subjects with and without treatement. \cite{rubin2006} represents with two letters L and D for 4 potential principle strata of the subjects, where L represents live and D stands for die. For example, if a person will live if treated but will die if not, he belongs to the stratum of LD. \cite{rubin2006} extends the causal effect from survival status to the outcomes observed. Similarly, we define $Y(1)$ and $Y(0)$ as the potential outcomes had the subject been exposed or not, respectively. However, these outcomes can only be observed if the subjects are still alive. Therefore, the causal effect of treatment on outcome is defined as
%
\begin{equation}
  \Delta_\text{LL} = \mathbb{E}\{Y(1)-Y(0)|G=\text{LL}\}.
  \label{eqn:sace}
\end{equation}
%
This is also known as the survivor average causal effect (SACE).

\subsection{Assumptions of the Model}

In real experiments, it is impossible to devide the subjects in the four strata \emph{a priori}. Those alive and treated belong to strata LL or LD, while those alive but not treated belong to LL or DL. The specific stratum LL is unidentifiable.

\cite{doi:10.1093/biostatistics/kxl027} assumes that
%
\begin{equation}
  S(1) \geq S(0) ~\text{a.s.}
  \label{ass:1}
\end{equation}
%
Let $W$ be the covariates of subjects, and \cite{doi:10.1093/biomet/70.1.41} referred as "strong ignorability of treatment assignment" to the assumption
%
\begin{equation}
  Z\ci S(z)|W\text{ for } z=0,1.
  \label{ass:2}
\end{equation}
%
In light of the "missing at random" assumption (\cite{doi:10.1093/biomet/63.3.581}), we have
%
\begin{equation}
  Z\ci Y(z)|W, G=\text{LL}\text{ for }z=0,1.
  \label{ass:3}
\end{equation}
%

Let baseline covariates $W=(X,A)$ where $X$ is similar to a confounder while $A$ is a substitution variable, which satisfies the substitution and exclusion assumption (\cite{10.1515/jci-2015-0024})
%
\begin{equation}n
  \begin{aligned}
  &A\ci Y(1)|Z=1,G,X,\\
  &A\nci G|Z=1,S=1,X,
  \end{aligned}
  \label{ass:4}
\end{equation}
%
and the SACE (Eqn.\ref{eqn:sace}) is identifiable with assumptions Eqn.\ref{ass:1}-\ref{ass:4} on the variables (\cite{Wang2017Identification}).

\subsection{Identification of SACE}

We illustrate hereafter the main points in the proof by \cite{Wang2017Identification}.
%
\begin{equation}
\mathbb{E}(Y(z)|G=\text{LL})=\frac{\mathbb{E}_w(\mu_{z,\text{LL},w}\cdot\pi_{\text{LL}|w})}{\mathbb{E}_w(\pi_{\text{LL}|w})},
\label{eqn::mu}
\end{equation}
where $\mu_{z,g,w}=\mathbb{E}(Y(z)|G=g,W=w)$ and $\pi_{g|w}=\mathbb{P}(G=g|W=w)$.

Under Eqn.\ref{ass:3}, 
\begin{equation}
\mu_{z,g,w}=\mathbb{E}(Y(z)|Z=z,G=g,W=w)=\mathbb{E}(Y|Z=z,G=g,W=w).
\end{equation}

Under Eqn.\ref{ass:1} and Eqn.\ref{ass:2},
\begin{equation}
  \pi_{\text{LL}|w}=\mathbb{P}(S(0)=1,S(1)=1|W=w)=\mathbb{P}(S(0)=1|W=w)=\mathbb{P}(S=1|Z=0,W=w).
\end{equation}
\begin{equation}
  \pi_{\text{LD}|w}=\mathbb{P}(S(0)=0,S(1)=1|W=w)=\mathbb{P}(S=1|Z=1,W=w)-\mathbb{P}(S=1|Z=0,W=w).
\end{equation}
From Eqn.\ref{eqn::mu},
\begin{equation}
  \mu_{0,\text{LL},w} = \mathbb{E}(Y|Z=0,S=1,W=w).
\end{equation}
Since $Y,Z,S$ and $W$ are all observable from the data, $\pi_{\text{LL}|w}$, $\pi_{\text{LD}|w}$ and $\mu_{0,\text{LL},w}$ are identifiable.

Denote $W$ in the form of $(X,A)$, and define
\begin{equation}
  p_{g|z,x,a,s}=\frac{\mathbb{P}(G=g|X=x,A=a)}{\mathbb{P}(S=s|Z=z,X=x,A=a)}.
\end{equation}
It can be proven that under Eqn.\ref{ass:4},
\begin{equation}
  \mathbb{E}(Y|Z=1,S=1,X=x,A=a)=p_{\text{LL}|1,x,a,1}\mu_{1,\text{LL},x}+(1-p_{\text{LL},1,x,a,1})\mu_{1,\text{LD},x}.
  \label{eqn::eqn}
\end{equation}
For $\forall x$, there exist different $a_1$ and $a_2$ satisfying Eqn.\ref{eqn::eqn} (under Eqn.\ref{ass:4}), and thus $\mu_{1,\text{LL},x}$ can be identified.

\subsection{Model Parameterization}\label{subsec:ModelParameterization}
For simplicity, we use (generalized) linear model as our assumption.

\begin{equation}
  \mu_{0,\text{LL},W} = \mathbb{E}(Y|Z=0,S=1,X,A) = \alpha_{10} + X\alpha_{11}+A\alpha_{12}.
\end{equation}
\begin{equation}
  \mu_{1,\text{L}\cdot,W} = \mathbb{E}(Y|Z=1,S(0)=L,S(1)=1,X,A) = \alpha_{20} + X\alpha_{21}+L\alpha_{22}.
  \label{eqn::mu1}
\end{equation}
In Eqn.\ref{eqn::mu1}, $A$ is dropped because under Eqn.\ref{ass:4}, $A\ci Y(1)|Z=1,S(0)=L,S(1)=1,X$. $L$ is not observable when $S(1)=1$, so we need to figure out later how to estimate $L$.

\begin{equation}
  \mathbb{P}(S=1|Z=1,W) = \expit(\beta_{0}+X\beta_{1}+A\beta_2).
\end{equation}
\begin{equation}
  \frac{\mathbb{P}(S=1|Z=0,W)}{\mathbb{P}(S=1|Z=1,W)} = \expit(\gamma_{0}+X\gamma_{1}+A\gamma_2).
\end{equation}
One can verify that these assumptions on the parameterization satisfy the requirements of the model.

\section{Parameter Estimation} \label{sec:ParameterEstimation}

\subsection{Data}

The data input should include multiple observations on random variables $Z,S,Y,X$ and $A$. Suppose the $i$-th observation can be denoted by $(Z^i,S^i,Y^i,X^i,A^i)$, and they denote respectively:
\begin{itemize}
  \item $Z^i$: an integer valued $0$ or $1$, exposure indicator of the $i$-th subject;
  \item $S^i$: an integer valued $0$ or $1$, survival indicator of the $i$-th subject;
  \item $Y^i$: a numeric vector, indicating the survival outcome of the $i$-th subject;
  \begin{itemize}
    \item $Y^i$ is discarded where $S^i=0$.
    \item A warning will be raised if $Y^i$ is NA where $S^i=1$.
  \end{itemize}
  \item $X^i$: a numeric row vector, the confounder of covariate $W$ of the $i$-th subject.
  \item $A^i$: a numeric row vector, the substitution variable of covariate $W$ of the $i$-th subject.
\end{itemize}

Accordingly, the data type of observed data matrix $\mathbf{Z},\mathbf{S},\mathbf{Y},\mathbf{X}$ and $\mathbf{A}$ are defined as Table \ref{tbl::data}.
\begin{table}[!htbp]
  \centering
  \begin{tabular}{ccc}
    \toprule
    Variable & Data Type & Size \\
    \midrule
    $\mathbf{Z}$ & Logical Column Vector & $n$ \\
    $\mathbf{S}$ & Logical Column Vector & $n$ \\
    $\mathbf{Y}$ & Numeric Matrix & $n\times k$ \\
    $\mathbf{X}$ & Numeric Matrix & $n\times p$ \\
    $\mathbf{A}$ & Numeric Matrix & $n\times q$ \\
    \bottomrule
  \end{tabular}
  \label{tbl::data}
  \caption{Data Types of Observed Variables}
\end{table}

\subsection{Parameters}
In Sec. \ref{subsec:ModelParameterization}, we put forward four models with parameters $\alpha_0$, $\alpha_1$, $\beta$ and $\gamma$. Here we put it in the matrix form.

Let
\begin{equation}
  \alpha_1 = \left(
    \begin{array}{c}
      \alpha_{10}\\
      \alpha_{11}\\
      \alpha_{12}\\
    \end{array}
  \right),
  \alpha_2 = \left(
    \begin{array}{c}
      \alpha_{20}\\
      \alpha_{21}\\
      \alpha_{22}\\
    \end{array}
  \right),
  \beta = \left(
    \begin{array}{c}
      \beta_0\\
      \beta_1\\
      \beta_2\\
    \end{array}
  \right),
  \gamma = \left(
    \begin{array}{c}
      \gamma_0\\
      \gamma_1\\
      \gamma_2\\
    \end{array}
  \right),
\end{equation}
be the parameters, and let
\begin{equation}
  \begin{aligned}
  \mathbf{W} &= (\mathbf{X}~~\mathbf{A}),\\
  \widetilde{\mathbf{W}} &= (\mathbf{1}_n~~\mathbf{W}),\\
  \widetilde{\mathbf{X}}&=(\mathbf{1}_n~~\mathbf{X}).
  \end{aligned}
\end{equation}
be the observed data matrix of random variables $W$, $\widetilde{W}$ and $\widetilde{X}$ respectively, 
then our parametric model can be rewritten as
\begin{equation}
  \begin{aligned}
  \mathbb{E}(Y|Z=0,S=1,X,A)&=\widetilde{W}\alpha_1,\\
  \mathbb{E}(Y|Z=1,S(0)=L,S(1)=1,X,A)&=(\widetilde{X}~~L)\alpha_2,\\
  \mathbb{P}(S=1|Z=1,W) &= \expit(\widetilde{W}\beta),\\
  \frac{\mathbb{P}(S=1|Z=0,W)}{\mathbb{P}(S=1|Z=1,W)} &= \expit(\widetilde{W}\gamma).
  \end{aligned}
\end{equation}


\begin{table}[!htbp]
  \centering
  \begin{tabular}{ccc}
    \toprule
    Parameter & Data Type & Size \\
    \midrule
    $\alpha_1$ & Numeric Matrix & $(p+q+1)\times k$ \\
    $\alpha_2$ & Numeric Matrix & $(p+2)\times k$ \\
    $\beta$ & Numeric Vector & $p+q+1$\\
    $\gamma$ & Numeric Vector & $p+q+1$\\
    \bottomrule
  \end{tabular}
  \label{tbl::data}
  \caption{Data Types of Parameters}
\end{table}

\subsection{Estimating the Parameters}
\subsubsection{Estimating $\alpha_1$}
Since $$\mathbb{E}(Y|Z=0,S=1,X,A)=\widetilde{W}\alpha_1,$$ we apply the ordinary least square method (OLS) to estimate $\alpha_1$. Let $\mathbf{Y}_{01}$ and $\widetilde{\mathbf{W}}_{01}$ be the observed data of $Y$ and $\widetilde{W}$ in the subset where $Z=0$ and $S=1$, and the estimator of $\alpha_1$ can be
%
\begin{equation}
\widehat{\alpha}_1=(\transpose{\widetilde{\mathbf{W}}_{01}}\widetilde{\mathbf{W}}_{01})^{-1}\transpose{\widetilde{\mathbf{W}}_{01}}\mathbf{Y}_{01}.
\end{equation}
%

\subsubsection{Estimating $\alpha_2$}
It may be natural to apply here the same method how we estimate $\alpha_1$, but it can be rather tricky because $L$ is not observable.
By doing simple algebra, one can avoid the problem by taking expectation over $L$.

\begin{equation}
  \begin{aligned}
    \mathbb{E}(Y|Z=1,S(1)=1,X,A)=&\mathbb{E}(Y|Z=1,S(0)=0,S(1)=1,X,A)
    \mathbb{P}(S(0)=0|Z=1,S(1)=1,W)\\
    &+\mathbb{E}(Y|Z=1,S(0)=1,S(1)=1,X,A)\mathbb{P}(S(0)=1|Z=1,S(1)=1,W)\\
    =&(\widetilde{X}~~0)\alpha_2\mathbb{P}(S(0)=0|Z=1,S(1)=1,W)\\
    &+(\widetilde{X}~~1)\alpha_2\mathbb{P}(S(0)=1|Z=1,S(1)=1,W)\\
    =&(\widetilde{X}~~\mathbb{P}(S(0)=1|Z=1,S(1)=1,W))\\
    =&\left(\widetilde{X}~~\frac{\mathbb{P}(S=1|Z=0,W)}{\mathbb{P}(S=1|Z=1,W)}\right) \\
    =&\left(\widetilde{X}~~\expit(\widetilde{W}\gamma)\right).
  \end{aligned}
\end{equation}

Let $\mathbf{Y}_{11}$, $\widetilde{\mathbf{X}}_{11}$ and $\widetilde{\mathbf{W}}_{11}$ be the observed data of $Y$, $\widetilde{X}$ and $\widetilde{W}$ in the subset where $Z=1$ and $S=1$, $\widehat{\gamma}$ be the estimator of $\gamma$. Denote $\widetilde{\mathbf{XL}}_{11}=\left(\widetilde{\mathbf{X}}_{11}~~\expit(\widetilde{\mathbf{W}}_{11}\widehat{\gamma})\right)$, and the estimator of $\alpha_2$ can be
%
\begin{equation}
\widehat{\alpha}_2=(\transpose{\widetilde{\mathbf{XL}}_{11}}\widetilde{\mathbf{XL}}_{11})^{-1}\transpose{\widetilde{\mathbf{XL}}_{11}}\mathbf{Y}_{11}.
\end{equation}
%

\subsubsection{Estimating $\beta$ and $\gamma$}
Note that the model involving $\beta$ and $\gamma$ is equivalent to 
\begin{equation}
  \begin{aligned}
    S|Z=1,W&\sim \mathcal{B}(1,\expit(\widetilde{W}\beta)),\\
    S|Z=0,W&\sim \mathcal{B}(1,\expit(\widetilde{W}\beta)\expit(\widetilde{W}\gamma)).
  \end{aligned}
\end{equation}

Define
\begin{equation}
  \begin{aligned}
  L(\beta,\gamma|z,s,w) &= \mathbb{P}(S=s|\beta,\gamma,Z=z,W=w) \\
  &=\left\{
  \begin{aligned}
    &\expit(\widetilde{w}\beta), &z=1,s=1 \\
    &1-\expit(\widetilde{w}\beta),&z=1,s=0 \\
    &\expit(\widetilde{w}\beta)\expit(\widetilde{w}\gamma),&z=0,s=1 \\
    &1-\expit(\widetilde{w}\beta)\expit(\widetilde{w}\gamma).&z=0,s=0\\
  \end{aligned}
  \right.
  \end{aligned}
\end{equation}
and
\begin{equation}
  \begin{aligned}
    D_\beta L(\beta,\gamma|z,s,w) &= \frac{\partial}{\partial\beta}\ln L(\beta,\gamma|z,s,w) \\
    &=\left\{
    \begin{aligned}
      &(1-\expit(\widetilde{w}\beta))\widetilde{w}, &z=1,s=1 \\
      &-\expit(\widetilde{w}\beta)\widetilde{w},&z=1,s=0 \\
      &(1-\expit(\widetilde{w}\beta))\widetilde{w},&z=0,s=1 \\
      &-\frac{(1-\expit(\widetilde{w}\beta))}{\expit^{-1}(\widetilde{w}\beta)\expit^{-1}(\widetilde{w}\gamma)-1}\widetilde{w}.&z=0,s=0\\
    \end{aligned}
    \right.
    \end{aligned}
\end{equation}
\begin{equation}
  \begin{aligned}
    D_\gamma L(\beta,\gamma|z,s,w) &= \frac{\partial}{\partial\gamma}\ln L(\beta,\gamma|z,s,w) \\
    &=\left\{
    \begin{aligned}
      &0, &z=1\\
      &(1-\expit(\widetilde{w}\gamma))\widetilde{w},&z=0,s=1 \\
      &-\frac{(1-\expit(\widetilde{w}\gamma))}{\expit^{-1}(\widetilde{w}\beta)\expit^{-1}(\widetilde{w}\gamma)-1}\widetilde{w}.&z=0,s=0\\
    \end{aligned}
    \right.
    \end{aligned}
\end{equation}

Using maximum likelihood estimation,
\begin{equation}
  (\widehat\beta,\widehat\gamma) = \arg\max\sum_{i=1}^n\ln L(\beta,\gamma|z^i,s^i,w^i).
\end{equation}
%% -- Illustrations ------------------------------------------------------------

%% - Virtually all JSS manuscripts list source code along with the generated
%%   output. The style files provide dedicated environments for this.
%% - In R, the environments {Sinput} and {Soutput} - as produced by Sweave() or
%%   or knitr using the render_sweave() hook - are used (without the need to
%%   load Sweave.sty).
%% - Equivalently, {CodeInput} and {CodeOutput} can be used.
%% - The code input should use "the usual" command prompt in the respective
%%   software system.
%% - For R code, the prompt "R> " should be used with "+  " as the
%%   continuation prompt.
%% - Comments within the code chunks should be avoided - these should be made
%%   within the regular LaTeX text.

\section{Illustrations} \label{sec:illustrations}

For a simple illustration of basic Poisson and NB count regression the
\code{quine} data from the \pkg{MASS} package is used. This provides the number
of \code{Days} that children were absent from school in Australia in a
particular year, along with several covariates that can be employed as regressors.
The data can be loaded by
%
\begin{CodeChunk}
\begin{CodeInput}
R> data("quine", package = "MASS")
\end{CodeInput}
\end{CodeChunk}
%
and a basic frequency distribution of the response variable is displayed in
Figure~\ref{fig:quine}.

\begin{leftbar}
For code input and output, the style files provide dedicated environments.
Either the ``agnostic'' \verb|{CodeInput}| and \verb|{CodeOutput}| can be used
or, equivalently, the environments \verb|{Sinput}| and \verb|{Soutput}| as
produced by \fct{Sweave} or \pkg{knitr} when using the \code{render_sweave()}
hook. Please make sure that all code is properly spaced, e.g., using
\code{y = a + b * x} and \emph{not} \code{y=a+b*x}. Moreover, code input should
use ``the usual'' command prompt in the respective software system. For
\proglang{R} code, the prompt \code{"R> "} should be used with \code{"+  "} as
the continuation prompt. Generally, comments within the code chunks should be
avoided -- and made in the regular {\LaTeX} text instead. Finally, empty lines
before and after code input/output should be avoided (see above).
\end{leftbar}

As a first model for the \code{quine} data, we fit the basic Poisson regression
model. (Note that JSS prefers when the second line of code is indented by two
spaces.)
%
\begin{CodeChunk}
\begin{CodeInput}
R> m_pois <- glm(Days ~ (Eth + Sex + Age + Lrn)^2, data = quine,
+    family = poisson)
\end{CodeInput}
\end{CodeChunk}
%
To account for potential overdispersion we also consider a negative binomial
GLM.
%
\begin{CodeChunk}
\begin{CodeInput}
R> library("MASS")
R> m_nbin <- glm.nb(Days ~ (Eth + Sex + Age + Lrn)^2, data = quine)
\end{CodeInput}
\end{CodeChunk}
%
In a comparison with the BIC the latter model is clearly preferred.
%
\begin{CodeChunk}
\begin{CodeInput}
R> BIC(m_pois, m_nbin)
\end{CodeInput}
\begin{CodeOutput}
       df      BIC
m_pois 18 2046.851
m_nbin 19 1157.235
\end{CodeOutput}
\end{CodeChunk}
%
Hence, the full summary of that model is shown below.
%
\begin{CodeChunk}
\begin{CodeInput}
R> summary(m_nbin)
\end{CodeInput}
\begin{CodeOutput}
Call:
glm.nb(formula = Days ~ (Eth + Sex + Age + Lrn)^2, data = quine, 
    init.theta = 1.60364105, link = log)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.0857  -0.8306  -0.2620   0.4282   2.0898  

Coefficients: (1 not defined because of singularities)
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  3.00155    0.33709   8.904  < 2e-16 ***
EthN        -0.24591    0.39135  -0.628  0.52977    
SexM        -0.77181    0.38021  -2.030  0.04236 *  
AgeF1       -0.02546    0.41615  -0.061  0.95121    
AgeF2       -0.54884    0.54393  -1.009  0.31296    
AgeF3       -0.25735    0.40558  -0.635  0.52574    
LrnSL        0.38919    0.48421   0.804  0.42153    
EthN:SexM    0.36240    0.29430   1.231  0.21818    
EthN:AgeF1  -0.70000    0.43646  -1.604  0.10876    
EthN:AgeF2  -1.23283    0.42962  -2.870  0.00411 ** 
EthN:AgeF3   0.04721    0.44883   0.105  0.91622    
EthN:LrnSL   0.06847    0.34040   0.201  0.84059    
SexM:AgeF1   0.02257    0.47360   0.048  0.96198    
SexM:AgeF2   1.55330    0.51325   3.026  0.00247 ** 
SexM:AgeF3   1.25227    0.45539   2.750  0.00596 ** 
SexM:LrnSL   0.07187    0.40805   0.176  0.86019    
AgeF1:LrnSL -0.43101    0.47948  -0.899  0.36870    
AgeF2:LrnSL  0.52074    0.48567   1.072  0.28363    
AgeF3:LrnSL       NA         NA      NA       NA    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for Negative Binomial(1.6036) family taken to be 1)

    Null deviance: 235.23  on 145  degrees of freedom
Residual deviance: 167.53  on 128  degrees of freedom
AIC: 1100.5

Number of Fisher Scoring iterations: 1


              Theta:  1.604 
          Std. Err.:  0.214 

 2 x log-likelihood:  -1062.546 
\end{CodeOutput}
\end{CodeChunk}



%% -- Summary/conclusions/discussion -------------------------------------------

\section{Summary and discussion} \label{sec:summary}

\begin{leftbar}
As usual \dots
\end{leftbar}


%% -- Optional special unnumbered sections -------------------------------------

\section*{Computational details}

\begin{leftbar}
If necessary or useful, information about certain computational details
such as version numbers, operating systems, or compilers could be included
in an unnumbered section. Also, auxiliary packages (say, for visualizations,
maps, tables, \dots) that are not cited in the main text can be credited here.
\end{leftbar}

The results in this paper were obtained using
\proglang{R}~3.4.1 with the
\pkg{MASS}~7.3.47 package. \proglang{R} itself
and all packages used are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at
\url{https://CRAN.R-project.org/}.


\section*{Acknowledgments}

\begin{leftbar}
All acknowledgments (note the AE spelling) should be collected in this
unnumbered section before the references. It may contain the usual information
about funding and feedback from colleagues/reviewers/etc. Furthermore,
information such as relative contributions of the authors may be added here
(if any).
\end{leftbar}


%% -- Bibliography -------------------------------------------------------------
%% - References need to be provided in a .bib BibTeX database.
%% - All references should be made with \cite, \citet, \citep, \citealp etc.
%%   (and never hard-coded). See the FAQ for details.
%% - JSS-specific markup (\proglang, \pkg, \code) should be used in the .bib.
%% - Titles in the .bib should be in title case.
%% - DOIs should be included where available.

\bibliography{refs}


%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".

\newpage

\begin{appendix}

\section{More technical details} \label{app:technical}

\begin{leftbar}
Appendices can be included after the bibliography (with a page break). Each
section within the appendix should have a proper section title (rather than
just \emph{Appendix}).

For more technical style details, please check out JSS's style FAQ at
\url{https://www.jstatsoft.org/pages/view/style#frequently-asked-questions}
which includes the following topics:
\begin{itemize}
  \item Title vs.\ sentence case.
  \item Graphics formatting.
  \item Naming conventions.
  \item Turning JSS manuscripts into \proglang{R} package vignettes.
  \item Trouble shooting.
  \item Many other potentially helpful details\dots
\end{itemize}
\end{leftbar}


\section[Using BibTeX]{Using \textsc{Bib}{\TeX}} \label{app:bibtex}

\begin{leftbar}
References need to be provided in a \textsc{Bib}{\TeX} file (\code{.bib}). All
references should be made with \verb|\cite|, \verb|\citet|, \verb|\citep|,
\verb|\citealp| etc.\ (and never hard-coded). This commands yield different
formats of author-year citations and allow to include additional details (e.g.,
pages, chapters, \dots) in brackets. In case you are not familiar with these
commands see the JSS style FAQ for details.

Cleaning up \textsc{Bib}{\TeX} files is a somewhat tedious task -- especially
when acquiring the entries automatically from mixed online sources. However,
it is important that informations are complete and presented in a consistent
style to avoid confusions. JSS requires the following format.
\begin{itemize}
  \item JSS-specific markup (\verb|\proglang|, \verb|\pkg|, \verb|\code|) should
    be used in the references.
  \item Titles should be in title case.
  \item Journal titles should not be abbreviated and in title case.
  \item DOIs should be included where available.
  \item Software should be properly cited as well. For \proglang{R} packages
    \code{citation("pkgname")} typically provides a good starting point.
\end{itemize}
\end{leftbar}

\end{appendix}

%% -----------------------------------------------------------------------------


\end{document}
